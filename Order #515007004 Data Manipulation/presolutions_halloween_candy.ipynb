{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# initial imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Do not change this option; This allows the CodeGrade auto grading to function correctly\n",
    "pd.set_option('display.max_columns', 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14052\\3610203403.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# read_csv with iso-8859-1 encoding; using latin-1 would also work here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mcandy_full\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'candy.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'iso-8859-1'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# copy to new DF so that we can have a copy of the original import if needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcandy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcandy_full\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# read_csv with iso-8859-1 encoding; using latin-1 would also work here\n",
    "candy_full = pd.read_csv('candy.csv', encoding='iso-8859-1')\n",
    "\n",
    "# copy to new DF so that we can have a copy of the original import if needed\n",
    "candy = candy_full.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Let's take a brief look at the data by using `head()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# first five rows\n",
    "candy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Next, run the following code to see information about the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check info about the DataFrame\n",
    "candy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Notice that this did not print the columns as you might be used to seeing. According to the Pandas documentation:  \"If the DataFrame has more than max_cols columns, the truncated output is used. By default, the setting in pandas.options.display.max_info_columns is used.\"\n",
    "\n",
    "We can make the columns display by setting the `max_cols` argument equal to the number of columns in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check info, set max_cols\n",
    "candy.info(max_cols=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Of course, if you are just looking for the column names, you can just use a simple `for` loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print a list of column names\n",
    "for col in candy.columns:\n",
    "    print(col)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "This data set is pretty messy. Your goal is now to perform the following actions to get it to the point where it can be passed to a machine learning model.\n",
    "\n",
    "**Note: Unless the instructions ask you to do something different, please always update the original `candy` DataFrame for the exercises below.  The automatic grading in CodeGrade will check your final DataFrame and ensure that you have performed all required data manipulations.  Also, feel free to add additional cells as needed.**\n",
    "\n",
    "**Note 2: If you run your code through CodeGrade before you get to exercise 19, your indices might be different than what CodeGrade is expecting.  Just continue with the assignment and run your code again through CodeGrade after exercise 19 to see if that clears up the error.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Exercise1:** Taking a look at the column names, you may notice that some include the character `Õ`. This should instead be an apostrophe `'` mark. Rename the column names that include the `Õ` character and replace it with an apostrophe.\n",
    "\n",
    "Remember that you should be updating the `candy` DataFrame for the tasks listed as unless told differently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_cols = [col.replace(\"Õ\", \"'\") if \"Õ\" in col else col for col in candy.columns]\n",
    "candy.columns = new_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Q1:** How many duplicated rows are there in the file? Assume that a duplicate is any row that is *exactly* the same as another one. Save this number as `Q1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Q1 = candy.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Q2:** How many duplicated rows are there in the file if we were to assume that a duplicate is any row with the same `Internal ID` number as another. In other words, even if the other values are different, a row would count as a duplicate if it had the same `Internal ID` as another. Save this number as `Q2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Q2 = candy.duplicated(subset=['Internal ID']).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Exercise2:** Drop any duplicates from the `candy` DataFrame.  Duplicates are to be defined as any row with the same `Internal ID` as another. Use the default setting that keeps the first record from the duplicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "candy = candy.drop_duplicates(subset='Internal ID', keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Exercise3:** Your next task is to remove the following columns from the `candy` DataFrame as we will not use these columns for this project.  You are welcome to do further analysis on these columns but do not save your analysis in this notebook.\n",
    "\n",
    "Remove the following columns: `Internal ID`, `Q5: STATE, PROVINCE, COUNTY, ETC`, `Q7: JOY OTHER`, `Q8: DESPAIR OTHER`, `Q9: OTHER COMMENTS`, `Unnamed: 113`, `Click Coordinates (x, y)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "columns_to_remove = ['Internal ID', 'Q5: STATE, PROVINCE, COUNTY, ETC', 'Q7: JOY OTHER', 'Q8: DESPAIR OTHER', 'Q9: OTHER COMMENTS', 'Unnamed: 113', 'Click Coordinates (x, y)']\n",
    "\n",
    "candy = candy.drop(columns=columns_to_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Code Check:** As a check for the above exercises, the shape of your data should now be: `(2460, 113)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(candy.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Exercise4:** Let's now take a look at the `Q2: GENDER` column since this will be what we are trying to predict. Take a look at the value counts for this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(candy['Q2: GENDER'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Q3:** How many missing values are in the `Q2: GENDER` column? Save this as `Q3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Q3 = candy['Q2: GENDER'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Exercise5:** Using the `candy` DataFrame, remove all rows with a missing value in the `Q2: GENDER` column.  (This should overwrite and be saved as `candy` like you have been doing for the previous exercises.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "candy = candy.dropna(subset=['Q2: GENDER'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Exercise6:** For this project, we want to use binary classification, which predicts one of two classes. Because we are using a binary classification model, we will try to predict between `Male` or `Female`. Select only the rows that contain either `Male` or `Female` in the `Q2: GENDER` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "candy = candy[candy['Q2: GENDER'].isin(['Male', 'Female'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Code Check:** As a check for the above exercises, the shape of your data should now be: `(2305, 113)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(candy.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now, let's work on filling some of the missing data.  There are easier ways to do this with the sklearn library which you will learn about more in the machine learning classes, but for now, let's try to practice our Pandas skills."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Q4:** How many missing values are in the `Q1: GOING OUT?` column? Save this number as `Q4`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Q4 = candy['Q1: GOING OUT?'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Exercise7:** For a future analysis question, we are interested in those that we know will *definitely* go out for Halloween.  Because of this, fill all missing values in the `Q1: GOING OUT?` column with a `No` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "candy['Q1: GOING OUT?'].fillna('No', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Code Check:** Double check your above work and look at the value counts for the `Q1: GOING OUT?` column.  Make sure that you only have \"Yes\" and No\" values and that they add up to 2305, which is the number of rows you should have at this step in the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(candy['Q1: GOING OUT?'].value_counts())\n",
    "print(candy.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Exercise8:** To get ready for the next step, let's practice selecting all the columns: going from `Q6 | 100 Grand Bar` to `Q11: DAY`.  Save this slice as `candy_slice`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "candy_slice = candy.loc[:, 'Q6 | 100 Grand Bar':'Q11: DAY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Exercise9:** Now that you know how to slice the data, fill any missing values in the `candy` DataFrame for those columns (going from `Q6 | 100 Grand Bar` to `Q11: DAY`) with the string `NO_ANSWER`. **Make sure you are working with the `candy` DataFrame and not the `candy_slice` DataFrame.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "candy.loc[:, 'Q6 | 100 Grand Bar':'Q11: DAY'] = candy.loc[:, 'Q6 | 100 Grand Bar':'Q11: DAY'].fillna('NO_ANSWER')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Exercise10:** For all four `Q12: Media` columns in the `candy` DataFrame, fill the missing values with `0.0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "candy[['Q12: MEDIA [Daily Dish]',\n",
    "       'Q12: MEDIA [Science]',\n",
    "       'Q12: MEDIA [ESPN]',\n",
    "       'Q12: MEDIA [Yahoo]']] = candy[['Q12: MEDIA [Daily Dish]',\n",
    "                                       'Q12: MEDIA [Science]',\n",
    "                                       'Q12: MEDIA [ESPN]',\n",
    "                                       'Q12: MEDIA [Yahoo]']].fillna(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Code Check:** As a check for the above code, make sure that there are no missing values left for the `Q6` to `Q12` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(candy.loc[:, 'Q6 | 100 Grand Bar':'Q12: MEDIA [Yahoo]'].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now, let's look at the very messy `Q4: COUNTRY` column and see what we can do about it. First, run the code below to look at the different unique values in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check unique values\n",
    "candy['Q4: COUNTRY'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Code Check:** As a check for the Country column, check to see how many unique values are in the data.  You should have `115` different unique values for the `Q4: COUNTRY` column.  If you have less or more than this number, double check your work above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check the Q4: COUNTRY number of unique values\n",
    "candy['Q4: COUNTRY'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We want to clean up this data to only include four areas: USA, Canada, Europe (the continent, not necessarily the European Union), and Other.\n",
    "\n",
    "There are different ways to do this, but I would suggest that you look at the way we handled the `property_type` column in the `vienna` data set and the code in the `amenities_to_columns()` function in the module notebook.  These might be a little harder than those examples but they should give you a good baseline approach.\n",
    "\n",
    "You could use `replace()` for this step, and it is fine if you ultimately decide to do this, but I would suggest that you come up with a solution similar to what was shown in the `vienna` data cleaning notebook.  This method would be much more robust if you had many more values in your data.\n",
    "\n",
    "I suggest the following order for this section to make it easier:\n",
    "- Fill in all missing values with `Other`\n",
    "- Code Australia as `Other` (doing this step will help when trying to use `us` in the next step if you use string methods)\n",
    "- Combine all USA entries together as `USA`\n",
    "- Combine Canadian entries as `CA`\n",
    "- Combine European entries as `EU`\n",
    "- Everything else gets coded as `Other`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Exercise11:** Fill the missing values in the `Q4: Country` column with `Other`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "candy['Q4: COUNTRY'].fillna('Other', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Code Check:** Double check that there are no missing values in the `Q4: COUNTRY` column.  Also, double check the unique values to make sure that \"Other\" was added.  This should mean that you now have `116` unique values for this column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check missing Q4 values\n",
    "print(candy['Q4: COUNTRY'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check unique values\n",
    "print(candy['Q4: COUNTRY'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Exercise12:** Combine all Australia entries into `Other`.  Watch out for capitalization issues.  You should have `114` unique values after this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Code Australia as \"Other\"\n",
    "candy['Q4: COUNTRY'] = candy['Q4: COUNTRY'].str.replace('Australia', 'Other', case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(candy['Q4: COUNTRY'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Exercise13:** Combine all United States entries together into `USA`.  These would include the following:\n",
    "```\n",
    "'USA ', 'USA', 'us', 'usa', 'Us', 'US', 'Murica', 'United States', 'united states', 'Usa', 'United States ', 'United staes', 'United States of America', 'United states', 'u.s.a.', 'United States of America ', 'america', 'U.S.A.', 'unhinged states', 'united states of america', 'US of A', 'The United States', 'North Carolina ', 'Unied States', 'U S', 'u.s.', 'The United States of America', 'unite states','U.S.', 'USA? Hard to tell anymore..', \"'merica\", 'United State', 'United Sates', 'California', 'Unites States', 'USa', 'I pretend to be from Canada, but I am really from the United States.', 'Usa ', 'United Stated', 'New Jersey', 'United ststes', 'America', 'United Statss', 'murrika', 'USA! USA! USA!', 'USAA', 'united States ', 'N. America', 'USSA', 'U.S. ', 'u s a', 'United Statea', 'united ststes', 'USA USA USA!!!!'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Careful:** Some students try to use regex for this step with a string method.  Be careful as there is one response with the term \"subscribe\" in it.  If you create your regex incorrectly, your use of \"u.s.\" could mistakenly pick up this record because of the \"ubs\" contained in it and code it as \"USA\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define a list of all variations of \"United States\"\n",
    "us_variations = ['USA ', 'USA', 'us', 'usa', 'Us', 'US', 'Murica', 'United States', 'united states', 'Usa', 'United States ',\n",
    "                 'United staes', 'United States of America', 'United states', 'u.s.a.', 'United States of America ', 'america',\n",
    "                 'U.S.A.', 'unhinged states', 'united states of america', 'US of A', 'The United States', 'North Carolina ',\n",
    "                 'Unied States', 'U S', 'u.s.', 'The United States of America', 'unite states','U.S.', 'USA? Hard to tell anymore..',\n",
    "                 \"'merica\", 'United State', 'United Sates', 'California', 'Unites States', 'USa',\n",
    "                 'I pretend to be from Canada, but I am really from the United States.', 'Usa ', 'United Stated', 'New Jersey',\n",
    "                 'United ststes', 'America', 'United Statss', 'murrika', 'USA! USA! USA!', 'USAA', 'united States ', 'N. America',\n",
    "                 'USSA', 'U.S. ', 'u s a', 'United Statea', 'united ststes', 'USA USA USA!!!!', ]\n",
    "\n",
    "# Loop over each variation of \"United States\" and replace it with \"USA\"\n",
    "for us_variation in us_variations:\n",
    "    candy['Q4: COUNTRY'] = candy['Q4: COUNTRY'].str.lower().replace(us_variation, regex=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Code Check:** You should be merging the above values together into 1 (`USA`) and be left with 61 unique values after this step (including the `USA` value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check unique values\n",
    "unique_countries = candy['Q4: COUNTRY'].unique()\n",
    "print(len(unique_countries))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Exercise14:** Combine the Canadian entries (both upper and lower case) and label them as `CA`. Be careful as there are extra spaces, characters, and misspellings (Can, Canae).\n",
    "\n",
    "These values include:\n",
    "```\n",
    "'canada', 'Canada', 'canada ', 'Canada ', 'Can', 'Canae', 'Canada`', 'CANADA'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Code Check:** You should be merging 8 values together into 1 (`CA`) and be left with 54 unique values after this step (including the `CA` value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check unique values\n",
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Exercise15:** Combine the European entries and label them as `EU`. Again, we are looking at the continent of Europe and not necessarily the countries that are a part of the European Union.\n",
    "\n",
    "These values include:\n",
    "```\n",
    "'uk', 'United Kingdom', 'England', 'UK', 'france', 'finland', 'Netherlands', 'germany', 'Europe', 'U.K. ', 'Greece', 'France', 'Ireland', 'Uk', 'Germany', 'Scotland', 'UK ', 'Denmark', 'France ', 'Switzerland', 'Scotland ', 'The Netherlands', 'Ireland ', 'spain', 'Sweden', 'United kingdom'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Code Check:** You should be merging 26 entries together and be left with 29 unique values after this step (including the `EU` value)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check unique values\n",
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Exercise16:** Finally, combine the other entries and label them as `Other`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Code Check:** Double check that you only have four unique values in the `Q4: COUNTRY` column: `USA`, `Other`, `CA`, and `EU`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check values\n",
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Q5:** To double check that everything was coded correctly, save the value counts of the `Q4: COUNTRY` column as `Q5`.  You can check this once you run your CodeGrade check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "We now want to look at the `Q3: AGE` column. Let's look at all the unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check unique age values\n",
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Again, this is a pretty messy column of data. This is a good example of why those that create online surveys shouldn't allow the individual to just put any value into the field. But it is now our job to clean this up.\n",
    "\n",
    "**Exercise17:** Your task is to put these values into the following categorical bins: `unknown`, `17 and under`, `18-25`, `26-35`, `36-45`, `46-55`, and `56+`.\n",
    "\n",
    "- The category labels should exactly match the above.\n",
    "- Missing values should be replaced with the `unknown` category\n",
    "- To make things easier and avoid ambiguity, let's say that any value with text, even if we could determine the age, will be binned with the `unknown` category. For example: `sixty-nine` should be coded as `unknown`, `45-55` should be coded as `unknown`, `59 on the day after Halloween` should be coded as `unknown`, etc.\n",
    "- Ensure that the category labels are unordered but reorder the categories so that 'unknown' is listed in the first position. This is not really needed but will help us grade your assignment. The categories should be listed as follows: `Index(['unknown', '17 and under', '18-25', '26-35', '36-45', '46-55', '56+'], dtype='object')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "First, we will replace any non-numeric value (those with text as mentioned above) with a missing value.  This will allow you to turn the other values into floats so that you can bin them. Just don't forget to code the missing values as `unknown` when you are done.  To replace the non-numeric values, run the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'candy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14052\\3504321409.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# create True/False index\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mage_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcandy\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Q3: AGE'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnumeric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# for the index, fill missing values with False\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'candy' is not defined"
     ]
    }
   ],
   "source": [
    "### DO NOT CHANGE THIS CODE - RUN AS IS ###\n",
    "### This code replaces non-numeric values with a missing value to make your next step easier ###\n",
    "\n",
    "# create True/False index\n",
    "age_index = candy['Q3: AGE'].str.isnumeric()\n",
    "\n",
    "# for the index, fill missing values with False\n",
    "age_index = age_index.fillna(False)\n",
    "\n",
    "# select Age column for only those False values from index and code as missing\n",
    "candy.loc[~age_index, 'Q3: AGE'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Now, you can finish exercise 17 to bin the ages and write the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### ENTER REST OF CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Exercise18:** Double check yourself by checking the categories for the `Q3: AGE` column. It should output: `Index(['unknown', '17 and under', '18-25', '26-35', '36-45', '46-55', '56+'], dtype='object')`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# double check categories\n",
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Code Check:** To double check your above binning worked correctly, your value counts (sorted by the index) should be as follows:\n",
    "\n",
    "```\n",
    "unknown: 60\n",
    "17 and under: 49\n",
    "18-25: 85\n",
    "26-35: 520\n",
    "36-45: 768\n",
    "46-55: 525\n",
    "56+: 298\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "You can also double check some of your work up to this point by making sure that there are no missing values in the data set anymore."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Code Check:** Check to see if there are any missing values in the data set. Your output should show `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Exercise19:** Before you move on to the next section, reset the index for `candy` ensuring that it goes from 0 to n-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Feature Engineering\n",
    "\n",
    "Feature engineering is the process of transforming raw data into features that better represent the underlying problem to the predictive models.  In this section, we will create a new column called \"net_feelies\" (calculated by the authors as the total joy count minus the total despair count).\n",
    "\n",
    "First, let's narrow down our data to make working with it easier.\n",
    "\n",
    "**Exercise20:** Select only the Q6 candy columns (`Q6 | 100 Grand Bar` through `Q6 | York Peppermint Patties`) in the data set and save this as a new DataFrame called `candy_reduced`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Next, we will create two Series, one with JOY counts and one with DESPAIR counts to add to our `candy_reduced` data.\n",
    "\n",
    "**Exercise21:** Create a Series called `joy_count` that lists total counts for JOY for each column, making sure to keep it in the same order as the columns in the `candy_reduced` DataFrame. Hint: A simple way to do this is to filter the entire DataFrame for any `JOY` values and then use `count()`. See this [stackoverflow question](https://stackoverflow.com/questions/63103090/how-do-i-count-specific-values-across-multiple-columns-in-pandas) and answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Exercise22:** Same as above except you will create a Series called `despair_count` that lists the total counts for DESPAIR for each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Exercise23:** Take the transpose of the `candy_reduced` DataFrame and save this transposed data as `candy_reduced_transpose`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Exercise24:** Add a new column called \"joy_count\" using the `joy_count` Series above and a new column called 'despair_count\" using the `despair_count` Series above to the `candy_reduced_transpose` DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Exercise25:** Add a new column to the `candy_reduced_transpose` DataFrame called \"net_feelies\" that takes the `joy_count` column and subtracts the `despair_count` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Exercise26:** Select only the `joy_count`, `despair_count`, and `net_feelies` columns from the `candy_reduced_transpose` DataFrame. Sort this DataFrame in descending order by `net_feelies` and save this as `candy_net_sorted`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Encoding\n",
    "\n",
    "We now want to get the `candy` DataFrame ready to run a machine learning algorthim to determine if we could predict a person's gender based on what candy they prefer.\n",
    "\n",
    "You will learn more about this in the machine learning classes, but some algorithms work exclusively with numeric values. We will now turn all of our values into numeric values.  There are easier ways to do this with sklearn, which you will study in later courses, but we will use Pandas to perform these exercises for further practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Exercise27:** For grading purposes, we want to leave the `candy` DataFrame as is. Make a copy of the `candy` DataFrame and save this new DataFrame as `candy_encode`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Exercise28:** For the `candy_encode` DataFrame, replace any `Female` values with `0` and any `Male` values with `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Exercise29:** Again, you will learn more about this later, but we need to separate the column that we want to predict (called the response) and the columns that we will use to make the predictions (called the features).  **For both of the items below, make sure that the index is reset and goes from 0 to n-1.**\n",
    "\n",
    "- Select only the `Q2: GENDER` column from `candy_encode` and save this as `candy_response`.  **Note: This should be a Series.**\n",
    "- Drop the following columns from the `candy_encode` DataFrame: `Q2: GENDER`,`Q1: GOING OUT?`,`Q3: AGE`,`Q4: COUNTRY`,`Q10: DRESS`,`Q11: DAY`, `Q12: MEDIA [Daily Dish]`,`Q12: MEDIA [Science]`,`Q12: MEDIA [ESPN]`,`Q12: MEDIA [Yahoo]`.  Save the remaining columns as `candy_features`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Exercise30:** Use Panda's `get_dummies()` to encode the `candy_features` data, making sure to set `drop_first=True`. Save this as `candy_features_encoded`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### ENTER CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "**Code Check:** Make sure that the `candy`, `candy_features`, `candy_response` and `candy_features_encoded` have an index that goes from 0 to n-1 or your final CodeGrade tests will not pass."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Final Analysis\n",
    "\n",
    "Great work! You have now cleaned your data and prepared it to be passed to a machine learning model.\n",
    "\n",
    "I created models using Random Forest, Logistic Regression, and XGBoost algorithms, and they all returned around 70% accuracy rates. However, the other accuracy metrics (that you will learn about more in the machine learning classes) didn't look as good. Given the metrics that were calculated, I would say that based only on this data, using candy preference is not that great of an indicator of someone's gender.\n",
    "\n",
    "**Next Steps:**\n",
    "- Submit your notebook to CodeGrade to check your final DataFrames.\n",
    "- For those of you that would like more practice using Pandas, try answering these optional questions below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Optional Data Analysis Questions\n",
    "\n",
    "- How many rows were in the original, uncleaned data that you imported? How many rows are in the cleaned data? How many did we end up removing from the data set?\n",
    "- What percentage of respondents are planning to go out trick-or-treating?\n",
    "- What percentage of respondents 17 and younger are planning to go out for trick-or-treating?\n",
    "- What are the total value counts and the normalized percentages of the age categories from the age column?\n",
    "- What are the total counts and percentages for the gender column?\n",
    "- What are the breakdown of counts for the country column?\n",
    "- How many total respondents voted joy in candy corn and how many voted despair? Did more people vote joy or despair for candy corn?\n",
    "- How many people voted joy in Reese's Peanut Butter Cups? In Snickers? Did more people vote joy for Reese's Peanut Butter Cups or for Snickers?\n",
    "- How many people voted joy in Twix? In Kit Kats? Did more people vote joy for Twix or for Kit Kats?\n",
    "- How many people voted joy in white bread? For whole wheat items? Did more people vote joy for white bread or whole wheat items?\n",
    "- How many people voted joy for Bonkers the board game? For Bonkers the candy? Did more people vote joy for the board game or for the candy?\n",
    "- How many people voted joy for a box of raisins? For the Blue-Ray DVD of the Real Housewives of Orange County Season 9? Did more people vote joy for a box of raisins or for the DVD?\n",
    "- What is the favorite day of the week for the respondents (both by total counts and percentages)?\n",
    "- Do more respondents see 'white and gold' or 'blue and black' for the [color of the dress](https://en.wikipedia.org/wiki/The_dress) (both total counts and percentages)?\n",
    "- For those respondents that clicked on the media link (listed as Q12 columns on the survey), which link did they click on the most?\n",
    "- How many males voted joy for receiving a copy of the Real Housewives of Orange County Season 9 DVD for Halloween? Females? Those 17 or younger?\n",
    "- The authors tried a funny way to determine a respondent's political leaning. Note this was purely a joke and not meant to be scientific. How many total respondents voted joy in the following: Blue M&M's, Red M&M's, Green Party M&M's, Independent M&M's, and Abstained from M&M'ing?\n",
    "- Determine what candy/item from the `candy_reduced` DataFrame has the most number of JOY votes and the least number of JOY votes.\n",
    "- What candy/item has the most DESPAIR votes?\n",
    "- What candy/item has the most MEH votes?\n",
    "- What candy/item did the most people not recognize or have an opinion on? (According to the survey, the respondents were asked to leave a question blank if they did not know the item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
